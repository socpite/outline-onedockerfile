#!/bin/bash
# Outline Export Script
# Exports complete Outline workspace to a folder

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
EXPORT_DIR=""
INCLUDE_FILES=true
INCLUDE_MARKDOWN=true
FORMAT="json"
VERBOSE=false

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

usage() {
    echo "Usage: $0 [OPTIONS]"
    echo ""
    echo "Export Outline workspace data"
    echo ""
    echo "Options:"
    echo "  -d, --dir DIR          Export directory (required)"
    echo "  -f, --format FORMAT    Export format: json, sql, both (default: json)"
    echo "  --no-files            Skip file attachments export"
    echo "  --no-markdown         Skip markdown files export"
    echo "  -v, --verbose         Verbose output"
    echo "  -h, --help            Show this help"
    echo ""
    echo "Examples:"
    echo "  $0 -d /tmp/outline-export"
    echo "  $0 -d ./backup --format both --verbose"
    echo "  $0 -d ./backup --no-files --no-markdown"
}

log() {
    if [[ "$VERBOSE" == true ]]; then
        echo -e "${BLUE}[INFO]${NC} $1"
    fi
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
}

check_dependencies() {
    log "Checking dependencies..."
    
    if ! command -v psql &> /dev/null; then
        error "psql not found. Please install PostgreSQL client."
    fi
    
    if ! command -v pg_dump &> /dev/null; then
        error "pg_dump not found. Please install PostgreSQL client."
    fi
}

check_database_connection() {
    log "Checking database connection..."
    
    if ! psql "$DATABASE_URL" -c "SELECT 1;" &> /dev/null; then
        error "Cannot connect to database. Check DATABASE_URL environment variable."
    fi
    
    success "Database connection verified"
}

validate_document_content() {
    log "Validating document content..."
    
    # Check for documents with null content
    local null_content_count=$(psql "$DATABASE_URL" -t -c "SELECT COUNT(*) FROM documents WHERE content IS NULL;" 2>/dev/null | tr -d ' ' || echo "0")
    
    if [[ "$null_content_count" -gt 0 ]]; then
        warn "âš ï¸  Found $null_content_count documents with missing content!"
        warn "   This usually happens when exporting too quickly after editing."
        warn "   These documents will export with empty content."
        echo ""
        
        # Show which documents have issues
        psql "$DATABASE_URL" -c "SELECT title, \"updatedAt\" FROM documents WHERE content IS NULL ORDER BY \"updatedAt\" DESC;" 2>/dev/null || true
        echo ""
        
        read -p "Continue with export anyway? (y/N): " -n 1 -r
        echo
        if [[ ! $REPLY =~ ^[Yy]$ ]]; then
            echo "Export cancelled. Please wait a few seconds and try again."
            exit 0
        fi
    else
        log "All documents have valid content"
    fi
}

export_database_sql() {
    local sql_file="$EXPORT_DIR/database.sql"
    log "Exporting database to SQL: $sql_file"
    
    pg_dump "$DATABASE_URL" > "$sql_file"
    
    if [[ -f "$sql_file" ]]; then
        local size=$(du -h "$sql_file" | cut -f1)
        success "Database exported to SQL ($size)"
    else
        error "Failed to export database to SQL"
    fi
}

export_database_json() {
    local json_file="$EXPORT_DIR/workspace.json"
    log "Exporting database to JSON: $json_file"
    
    # Check if python3 is available for clean JSON export
    if ! command -v python3 &> /dev/null; then
        error "python3 is required for JSON export. Please install python3."
    fi
    
    # Create Python script for clean JSON export
    cat > /tmp/export_json.py << 'PYTHON_SCRIPT'
import json
import sys
import subprocess
import os
from datetime import datetime

def run_sql(sql, database_url):
    """Execute SQL command using psql and return result"""
    try:
        result = subprocess.run(['psql', database_url, '-t', '-c', sql], 
                              capture_output=True, text=True, check=True)
        return result.stdout.strip()
    except subprocess.CalledProcessError as e:
        return None

def export_table(table_name, database_url):
    """Export a table as clean JSON array"""
    sql = f"SELECT COALESCE(json_agg(row_to_json({table_name}.*)), '[]'::json) FROM {table_name};"
    result = run_sql(sql, database_url)
    
    if result:
        try:
            # Parse and re-serialize to ensure clean JSON
            data = json.loads(result)
            return data
        except json.JSONDecodeError:
            print(f"Warning: Failed to parse JSON for table {table_name}")
            return []
    else:
        print(f"Warning: Failed to export table {table_name}")
        return []

def main():
    if len(sys.argv) != 3:
        print("Usage: python3 export_json.py <database_url> <output_file>")
        sys.exit(1)
    
    database_url = sys.argv[1]
    output_file = sys.argv[2]
    
    # Export all tables
    tables = ["teams", "users", "collections", "documents", "attachments", 
              "shares", "stars", "pins", "views", "memberships", "groups", "group_users"]
    
    export_data = {
        "version": "1.0",
        "exportedAt": datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
    }
    
    for table in tables:
        print(f"Exporting table: {table}")
        export_data[table] = export_table(table, database_url)
    
    # Write clean JSON
    with open(output_file, 'w') as f:
        json.dump(export_data, f, indent=2, ensure_ascii=False)
    
    print(f"Export completed: {output_file}")

if __name__ == "__main__":
    main()
PYTHON_SCRIPT
    
    # Run the Python export script
    if python3 /tmp/export_json.py "$DATABASE_URL" "$json_file"; then
        if [[ -f "$json_file" ]]; then
            local size=$(du -h "$json_file" | cut -f1)
            success "Database exported to JSON ($size)"
        else
            error "Failed to create JSON file"
        fi
    else
        error "Failed to export database to JSON"
    fi
    
    # Clean up
    rm -f /tmp/export_json.py
}

export_files() {
    if [[ "$INCLUDE_FILES" != true ]]; then
        log "Skipping file attachments export"
        return
    fi
    
    local files_dir="$EXPORT_DIR/files"
    log "Exporting file attachments to: $files_dir"
    
    # Default file storage location
    local storage_dir="/var/lib/outline/data"
    
    if [[ ! -d "$storage_dir" ]]; then
        warn "File storage directory not found: $storage_dir"
        return
    fi
    
    mkdir -p "$files_dir"
    
    if cp -r "$storage_dir"/* "$files_dir"/ 2>/dev/null; then
        local size=$(du -sh "$files_dir" | cut -f1)
        success "Files exported ($size)"
    else
        warn "No files found to export or copy failed"
    fi
}

export_markdown() {
    local markdown_dir="$EXPORT_DIR/markdown"
    log "Exporting documents as markdown files to: $markdown_dir"
    
    # Check if we're in the Outline environment
    if [[ ! -f "/home/ubuntu/outline/package.json" ]]; then
        warn "Not in Outline environment - using simplified markdown export"
        export_markdown_simple "$markdown_dir"
        return
    fi
    
    # Create markdown export directory
    mkdir -p "$markdown_dir"
    
    # Create Node.js script that uses Outline's DocumentHelper
    cat > /tmp/export_markdown_outline.js << 'NODE_SCRIPT'
// This script runs in the Outline environment and uses DocumentHelper.toMarkdown
const path = require('path');
const fs = require('fs');

// Set up the Outline environment
process.chdir('/home/ubuntu/outline');
process.env.NODE_ENV = process.env.NODE_ENV || 'production';
process.env.NODE_PATH = '/home/ubuntu/outline/node_modules';

// Import Outline modules - try different paths
let Document, Collection, DocumentHelper;

try {
    // Try the build directory first (compiled JavaScript) - use absolute paths
    const models = require('/home/ubuntu/outline/build/server/models/index');
    Document = models.Document;
    Collection = models.Collection;
    
    const helpers = require('/home/ubuntu/outline/build/server/models/helpers/DocumentHelper');
    DocumentHelper = helpers.DocumentHelper;
    console.log('Successfully loaded built modules');
} catch (e1) {
    try {
        // Try individual file imports with absolute paths
        Document = require('/home/ubuntu/outline/build/server/models/Document').default;
        Collection = require('/home/ubuntu/outline/build/server/models/Collection').default;
        DocumentHelper = require('/home/ubuntu/outline/build/server/models/helpers/DocumentHelper').DocumentHelper;
        console.log('Successfully loaded individual modules');
    } catch (e2) {
        try {
            // Try direct server imports (TypeScript source) with absolute paths
            Document = require('/home/ubuntu/outline/server/models/Document').default;
            Collection = require('/home/ubuntu/outline/server/models/Collection').default;
            DocumentHelper = require('/home/ubuntu/outline/server/models/helpers/DocumentHelper').DocumentHelper;
            console.log('Successfully loaded source modules');
        } catch (e3) {
            console.error('Could not load Outline modules:');
            console.error('Error 1 (build index):', e1.message);
            console.error('Error 2 (individual):', e2.message);
            console.error('Error 3 (source):', e3.message);
            console.error('Available files in /home/ubuntu/outline:');
            try {
                const files = fs.readdirSync('/home/ubuntu/outline');
                console.error(files.join(', '));
                console.error('Available files in /home/ubuntu/outline/build/server/models:');
                const buildFiles = fs.readdirSync('/home/ubuntu/outline/build/server/models');
                console.error(buildFiles.join(', '));
            } catch (e4) {
                console.error('Could not list directory');
            }
            process.exit(1);
        }
    }
}

// Function to sanitize filename
function sanitizeFilename(filename) {
    return filename
        .replace(/[<>:"/\\|?*]/g, '_')
        .replace(/\s+/g, '_')
        .replace(/_{2,}/g, '_')
        .replace(/^_+|_+$/g, '')
        .substring(0, 200);
}

async function exportMarkdown() {
    const outputDir = process.argv[2];
    if (!outputDir) {
        console.error('Usage: node export_markdown_outline.js <output_directory>');
        process.exit(1);
    }
    
    try {
        console.log('Fetching documents from database...');
        console.log('Using Document model:', !!Document);
        console.log('Using Collection model:', !!Collection);
        console.log('Using DocumentHelper:', !!DocumentHelper);
        
        // Get all documents with their collections
        const documents = await Document.findAll({
            include: [
                {
                    model: Collection,
                    as: 'collection',
                    required: false
                }
            ],
            where: {
                deletedAt: null
            },
            order: [
                [{ model: Collection, as: 'collection' }, 'name', 'ASC NULLS LAST'],
                ['title', 'ASC']
            ]
        });
        
        if (documents.length === 0) {
            console.log('No documents found to export.');
            return;
        }
        
        console.log(`Found ${documents.length} documents to export.`);
        
        // Group documents by collection
        const collections = {};
        for (const doc of documents) {
            const collectionName = doc.collection?.name || 'Uncategorized';
            if (!collections[collectionName]) {
                collections[collectionName] = [];
            }
            collections[collectionName].push(doc);
        }
        
        let exportedCount = 0;
        
        // Export documents
        for (const [collectionName, docs] of Object.entries(collections)) {
            console.log(`Exporting collection: ${collectionName} (${docs.length} documents)`);
            
            // Create collection directory
            const collectionDir = path.join(outputDir, sanitizeFilename(collectionName));
            if (!fs.existsSync(collectionDir)) {
                fs.mkdirSync(collectionDir, { recursive: true });
            }
            
            for (const doc of docs) {
                try {
                    // Use Outline's built-in DocumentHelper.toMarkdown
                    const markdown = DocumentHelper.toMarkdown(doc, { includeTitle: true });
                    const filename = sanitizeFilename(doc.title) + '.md';
                    const filepath = path.join(collectionDir, filename);
                    
                    // Add metadata header
                    const metadata = `---
title: "${doc.title}"
created: ${doc.createdAt}
updated: ${doc.updatedAt}
collection: "${collectionName}"
id: ${doc.id}
---

`;
                    
                    fs.writeFileSync(filepath, metadata + markdown);
                    exportedCount++;
                    
                    if (exportedCount % 10 === 0) {
                        console.log(`Exported ${exportedCount} documents...`);
                    }
                } catch (error) {
                    console.error(`Error exporting document "${doc.title}":`, error.message);
                    // Create a basic file even if conversion fails
                    const filename = sanitizeFilename(doc.title) + '.md';
                    const filepath = path.join(collectionDir, filename);
                    const basicContent = `---
title: "${doc.title}"
created: ${doc.createdAt}
updated: ${doc.updatedAt}
collection: "${collectionName}"
id: ${doc.id}
---

# ${doc.title}

*Error converting document content: ${error.message}*
`;
                    fs.writeFileSync(filepath, basicContent);
                    exportedCount++;
                }
            }
        }
        
        console.log(`Successfully exported ${exportedCount} documents to ${outputDir}`);
        
        // Create index file
        const indexPath = path.join(outputDir, 'README.md');
        let indexContent = `# Exported Documents\n\nExported ${exportedCount} documents on ${new Date().toISOString()}\n\n`;
        
        for (const [collectionName, docs] of Object.entries(collections)) {
            indexContent += `## ${collectionName} (${docs.length} documents)\n\n`;
            for (const doc of docs) {
                const filename = sanitizeFilename(doc.title) + '.md';
                const collectionDir = sanitizeFilename(collectionName);
                indexContent += `- [${doc.title}](${collectionDir}/${filename})\n`;
            }
            indexContent += '\n';
        }
        
        fs.writeFileSync(indexPath, indexContent);
        console.log(`Created index file: ${indexPath}`);
        
    } catch (error) {
        console.error('Error during markdown export:', error);
        console.error('Stack trace:', error.stack);
        process.exit(1);
    }
}

exportMarkdown();
NODE_SCRIPT
    
    # Run the Node.js export script in the Outline environment
    if cd /home/ubuntu/outline && NODE_PATH="/home/ubuntu/outline/node_modules" node /tmp/export_markdown_outline.js "$markdown_dir"; then
        local size=$(du -sh "$markdown_dir" | cut -f1)
        success "Markdown files exported using Outline's DocumentHelper ($size)"
    else
        warn "Failed to use Outline's DocumentHelper, falling back to simple export"
        export_markdown_simple "$markdown_dir"
    fi
    
    # Clean up
    rm -f /tmp/export_markdown_outline.js
}

export_markdown_simple() {
    local markdown_dir="$1"
    log "Using simplified markdown export (text field only)"
export_markdown_simple() {
    local markdown_dir="$1"
    log "Using simplified markdown export (text field only)"
    
    # Create Node.js script for simple markdown export
    cat > /tmp/export_markdown_simple.js << 'NODE_SCRIPT'
const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');

// Function to sanitize filename
function sanitizeFilename(filename) {
    return filename
        .replace(/[<>:"/\\|?*]/g, '_')
        .replace(/\s+/g, '_')
        .replace(/_{2,}/g, '_')
        .replace(/^_+|_+$/g, '')
        .substring(0, 200);
}

// Function to execute SQL and return result
function runSQL(sql) {
    try {
        const result = execSync(`psql "${process.env.DATABASE_URL}" -t -A -F'|' -c "${sql.replace(/"/g, '\\"')}"`, 
                               { encoding: 'utf8' });
        return result.trim();
    } catch (error) {
        console.error('SQL Error:', error.message);
        return null;
    }
}

// Function to get documents with collection info
function getDocuments() {
    const sql = `
        SELECT 
            d.id,
            d.title,
            COALESCE(d.text, '') as text,
            d."createdAt",
            d."updatedAt",
            COALESCE(c.name, 'Uncategorized') as collection_name,
            d.icon
        FROM documents d
        LEFT JOIN collections c ON d."collectionId" = c.id
        WHERE d."deletedAt" IS NULL
        ORDER BY c.name NULLS LAST, d.title;
    `;
    
    const result = runSQL(sql);
    if (!result) return [];
    
    try {
        const rows = result.split('\n').filter(row => row.trim());
        const documents = [];
        
        for (const row of rows) {
            const parts = row.split('|');
            if (parts.length >= 6) {
                documents.push({
                    id: parts[0] || '',
                    title: parts[1] || 'Untitled',
                    text: parts[2] || '',
                    createdAt: parts[3] || '',
                    updatedAt: parts[4] || '',
                    collection_name: parts[5] || 'Uncategorized',
                    icon: parts[6] || ''
                });
            }
        }
        
        return documents;
    } catch (error) {
        console.error('Error parsing documents:', error.message);
        return [];
    }
}

// Function to convert document to markdown
function convertToMarkdown(document) {
    try {
        let content = document.text || '';
        
        // Clean up content
        content = content
            .replace(/\\n/g, '\n')
            .replace(/\\\\/g, '\\')
            .trim();
        
        // If content is empty or just whitespace/backslashes
        if (!content || content === '\\' || content === '\n' || content.match(/^[\\\s\n]*$/)) {
            content = '*This document appears to be empty.*';
        }
        
        // Add title with icon if present
        let title = document.title;
        if (document.icon && document.icon.trim()) {
            title = `${document.icon} ${title}`;
        }
        
        // Add title if not already present as heading
        if (!content.startsWith('#')) {
            content = `# ${title}\n\n${content}`;
        }
        
        return content;
    } catch (error) {
        console.error(`Error converting document ${document.id}:`, error.message);
        return `# ${document.title}\n\n*Error converting document content.*\n`;
    }
}

// Main export function
function exportMarkdown() {
    const outputDir = process.argv[2];
    if (!outputDir) {
        console.error('Usage: node export_markdown_simple.js <output_directory>');
        process.exit(1);
    }
    
    console.log('Fetching documents...');
    const documents = getDocuments();
    
    if (documents.length === 0) {
        console.log('No documents found to export.');
        return;
    }
    
    console.log(`Found ${documents.length} documents to export.`);
    
    // Group documents by collection
    const collections = {};
    for (const doc of documents) {
        const collectionName = doc.collection_name || 'Uncategorized';
        if (!collections[collectionName]) {
            collections[collectionName] = [];
        }
        collections[collectionName].push(doc);
    }
    
    let exportedCount = 0;
    
    // Export documents
    for (const [collectionName, docs] of Object.entries(collections)) {
        console.log(`Exporting collection: ${collectionName} (${docs.length} documents)`);
        
        // Create collection directory
        const collectionDir = path.join(outputDir, sanitizeFilename(collectionName));
        if (!fs.existsSync(collectionDir)) {
            fs.mkdirSync(collectionDir, { recursive: true });
        }
        
        for (const doc of docs) {
            try {
                const markdown = convertToMarkdown(doc);
                const filename = sanitizeFilename(doc.title) + '.md';
                const filepath = path.join(collectionDir, filename);
                
                // Add metadata header
                const metadata = `---
title: "${doc.title}"
created: ${doc.createdAt}
updated: ${doc.updatedAt}
collection: "${collectionName}"
id: ${doc.id}
---

`;
                
                fs.writeFileSync(filepath, metadata + markdown);
                exportedCount++;
                
                if (exportedCount % 10 === 0) {
                    console.log(`Exported ${exportedCount} documents...`);
                }
            } catch (error) {
                console.error(`Error exporting document "${doc.title}":`, error.message);
            }
        }
    }
    
    console.log(`Successfully exported ${exportedCount} documents to ${outputDir}`);
    
    // Create index file
    const indexPath = path.join(outputDir, 'README.md');
    let indexContent = `# Exported Documents\n\nExported ${exportedCount} documents on ${new Date().toISOString()}\n\n`;
    
    for (const [collectionName, docs] of Object.entries(collections)) {
        indexContent += `## ${collectionName} (${docs.length} documents)\n\n`;
        for (const doc of docs) {
            const filename = sanitizeFilename(doc.title) + '.md';
            const collectionDir = sanitizeFilename(collectionName);
            indexContent += `- [${doc.title}](${collectionDir}/${filename})\n`;
        }
        indexContent += '\n';
    }
    
    fs.writeFileSync(indexPath, indexContent);
    console.log(`Created index file: ${indexPath}`);
}

exportMarkdown();
NODE_SCRIPT
    
    # Run the simple export script
    if node /tmp/export_markdown_simple.js "$markdown_dir"; then
        local size=$(du -sh "$markdown_dir" | cut -f1)
        success "Markdown files exported using simple method ($size)"
    else
        error "Failed to export markdown files"
    fi
    
    # Clean up
    rm -f /tmp/export_markdown_simple.js
}
}

create_metadata() {
    local metadata_file="$EXPORT_DIR/export_metadata.json"
    log "Creating export metadata: $metadata_file"
    
    cat > "$metadata_file" << EOF
{
    "version": "1.0",
    "exportedAt": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
    "exportedBy": "outline-export-cli",
    "format": "$FORMAT",
    "includeFiles": $INCLUDE_FILES,
    "includeMarkdown": $INCLUDE_MARKDOWN,
    "databaseUrl": "$(echo "$DATABASE_URL" | sed 's/:[^:]*@/:***@/')",
    "hostname": "$(hostname)",
    "outlineVersion": "$(node -p "require('/home/ubuntu/outline/package.json').version" 2>/dev/null || echo 'unknown')"
}
EOF
    
    success "Export metadata created"
}

create_readme() {
    local readme_file="$EXPORT_DIR/README.md"
    log "Creating README: $readme_file"
    
    cat > "$readme_file" << EOF
# Outline Export

This directory contains a complete export of an Outline workspace.

## Export Details

- **Exported At**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
- **Format**: $FORMAT
- **Include Files**: $INCLUDE_FILES
- **Include Markdown**: $INCLUDE_MARKDOWN

## Contents

EOF

    if [[ "$FORMAT" == "sql" || "$FORMAT" == "both" ]]; then
        echo "- \`database.sql\` - Complete database dump" >> "$readme_file"
    fi
    
    if [[ "$FORMAT" == "json" || "$FORMAT" == "both" ]]; then
        echo "- \`workspace.json\` - Structured workspace data" >> "$readme_file"
    fi
    
    if [[ "$INCLUDE_FILES" == true ]]; then
        echo "- \`files/\` - File attachments and uploads" >> "$readme_file"
    fi
    
    if [[ "$INCLUDE_MARKDOWN" == true ]]; then
        echo "- \`markdown/\` - All documents exported as markdown files" >> "$readme_file"
    fi
    
    cat >> "$readme_file" << EOF
- \`export_metadata.json\` - Export metadata and settings
- \`README.md\` - This file

## Import

To import this data into another Outline instance, use:

\`\`\`bash
outline-import -d $(basename "$EXPORT_DIR")
\`\`\`

## Manual Import

### Database (SQL)
\`\`\`bash
psql \$DATABASE_URL < database.sql
\`\`\`

### Files
\`\`\`bash
cp -r files/* /var/lib/outline/data/
\`\`\`
EOF
    
    success "README created"
}

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -d|--dir)
            EXPORT_DIR="$2"
            shift 2
            ;;
        -f|--format)
            FORMAT="$2"
            shift 2
            ;;
        --no-files)
            INCLUDE_FILES=false
            shift
            ;;
        --no-markdown)
            INCLUDE_MARKDOWN=false
            shift
            ;;
        -v|--verbose)
            VERBOSE=true
            shift
            ;;
        -h|--help)
            usage
            exit 0
            ;;
        *)
            error "Unknown option: $1"
            ;;
    esac
done

# Validate arguments
if [[ -z "$EXPORT_DIR" ]]; then
    error "Export directory is required. Use -d or --dir option."
fi

if [[ "$FORMAT" != "json" && "$FORMAT" != "sql" && "$FORMAT" != "both" ]]; then
    error "Invalid format: $FORMAT. Use json, sql, or both."
fi

# Check for DATABASE_URL
if [[ -z "$DATABASE_URL" ]]; then
    error "DATABASE_URL environment variable is required."
fi

# Main execution
echo "ðŸš€ Starting Outline export..."
echo "ðŸ“ Export directory: $EXPORT_DIR"
echo "ðŸ“‹ Format: $FORMAT"
echo "ðŸ“Ž Include files: $INCLUDE_FILES"
echo "ðŸ“ Include markdown: $INCLUDE_MARKDOWN"
echo ""

# Warning about export timing
warn "âš ï¸  IMPORTANT: If you just edited documents, wait 5-10 seconds before exporting"
warn "   to ensure all changes are saved. Exporting too quickly after edits may"
warn "   result in missing document content due to autosave timing."
echo ""

check_dependencies
check_database_connection
validate_document_content

# Create export directory
mkdir -p "$EXPORT_DIR"
log "Created export directory: $EXPORT_DIR"

# Export based on format
if [[ "$FORMAT" == "sql" || "$FORMAT" == "both" ]]; then
    export_database_sql
fi

if [[ "$FORMAT" == "json" || "$FORMAT" == "both" ]]; then
    export_database_json
fi

# Export files
export_files

# Export markdown
if [[ "$INCLUDE_MARKDOWN" == true ]]; then
    export_markdown
fi

# Create metadata and documentation
create_metadata
create_readme

echo ""
success "Export completed successfully!"
echo "ðŸ“ Export location: $EXPORT_DIR"
echo "ðŸ“Š Export size: $(du -sh "$EXPORT_DIR" | cut -f1)"
echo ""
echo "To import this data, use:"
echo "  outline-import -d $EXPORT_DIR"