#!/bin/bash
# Outline Export Script
# Exports complete Outline workspace to a folder

set -e

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
EXPORT_DIR=""
INCLUDE_FILES=true
FORMAT="json"
VERBOSE=false

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

usage() {
    echo "Usage: $0 [OPTIONS]"
    echo ""
    echo "Export Outline workspace data"
    echo ""
    echo "Options:"
    echo "  -d, --dir DIR          Export directory (required)"
    echo "  -f, --format FORMAT    Export format: json, sql, both (default: json)"
    echo "  --no-files            Skip file attachments export"
    echo "  -v, --verbose         Verbose output"
    echo "  -h, --help            Show this help"
    echo ""
    echo "Examples:"
    echo "  $0 -d /tmp/outline-export"
    echo "  $0 -d ./backup --format both --verbose"
    echo "  $0 -d ./backup --no-files"
}

log() {
    if [[ "$VERBOSE" == true ]]; then
        echo -e "${BLUE}[INFO]${NC} $1"
    fi
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
}

check_dependencies() {
    log "Checking dependencies..."
    
    if ! command -v psql &> /dev/null; then
        error "psql not found. Please install PostgreSQL client."
    fi
    
    if ! command -v pg_dump &> /dev/null; then
        error "pg_dump not found. Please install PostgreSQL client."
    fi
}

check_database_connection() {
    log "Checking database connection..."
    
    if ! psql "$DATABASE_URL" -c "SELECT 1;" &> /dev/null; then
        error "Cannot connect to database. Check DATABASE_URL environment variable."
    fi
    
    success "Database connection verified"
}

validate_document_content() {
    log "Validating document content..."
    
    # Check for documents with null content
    local null_content_count=$(psql "$DATABASE_URL" -t -c "SELECT COUNT(*) FROM documents WHERE content IS NULL;" 2>/dev/null | tr -d ' ' || echo "0")
    
    if [[ "$null_content_count" -gt 0 ]]; then
        warn "âš ï¸  Found $null_content_count documents with missing content!"
        warn "   This usually happens when exporting too quickly after editing."
        warn "   These documents will export with empty content."
        echo ""
        
        # Show which documents have issues
        psql "$DATABASE_URL" -c "SELECT title, \"updatedAt\" FROM documents WHERE content IS NULL ORDER BY \"updatedAt\" DESC;" 2>/dev/null || true
        echo ""
        
        read -p "Continue with export anyway? (y/N): " -n 1 -r
        echo
        if [[ ! $REPLY =~ ^[Yy]$ ]]; then
            echo "Export cancelled. Please wait a few seconds and try again."
            exit 0
        fi
    else
        log "All documents have valid content"
    fi
}

export_database_sql() {
    local sql_file="$EXPORT_DIR/database.sql"
    log "Exporting database to SQL: $sql_file"
    
    pg_dump "$DATABASE_URL" > "$sql_file"
    
    if [[ -f "$sql_file" ]]; then
        local size=$(du -h "$sql_file" | cut -f1)
        success "Database exported to SQL ($size)"
    else
        error "Failed to export database to SQL"
    fi
}

export_database_json() {
    local json_file="$EXPORT_DIR/workspace.json"
    log "Exporting database to JSON: $json_file"
    
    # Check if python3 is available for clean JSON export
    if ! command -v python3 &> /dev/null; then
        error "python3 is required for JSON export. Please install python3."
    fi
    
    # Create Python script for clean JSON export
    cat > /tmp/export_json.py << 'PYTHON_SCRIPT'
import json
import sys
import subprocess
import os
from datetime import datetime

def run_sql(sql, database_url):
    """Execute SQL command using psql and return result"""
    try:
        result = subprocess.run(['psql', database_url, '-t', '-c', sql], 
                              capture_output=True, text=True, check=True)
        return result.stdout.strip()
    except subprocess.CalledProcessError as e:
        return None

def export_table(table_name, database_url):
    """Export a table as clean JSON array"""
    sql = f"SELECT COALESCE(json_agg(row_to_json({table_name}.*)), '[]'::json) FROM {table_name};"
    result = run_sql(sql, database_url)
    
    if result:
        try:
            # Parse and re-serialize to ensure clean JSON
            data = json.loads(result)
            return data
        except json.JSONDecodeError:
            print(f"Warning: Failed to parse JSON for table {table_name}")
            return []
    else:
        print(f"Warning: Failed to export table {table_name}")
        return []

def main():
    if len(sys.argv) != 3:
        print("Usage: python3 export_json.py <database_url> <output_file>")
        sys.exit(1)
    
    database_url = sys.argv[1]
    output_file = sys.argv[2]
    
    # Export all tables
    tables = ["teams", "users", "collections", "documents", "attachments", 
              "shares", "stars", "pins", "views", "memberships", "groups", "group_users"]
    
    export_data = {
        "version": "1.0",
        "exportedAt": datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
    }
    
    for table in tables:
        print(f"Exporting table: {table}")
        export_data[table] = export_table(table, database_url)
    
    # Write clean JSON
    with open(output_file, 'w') as f:
        json.dump(export_data, f, indent=2, ensure_ascii=False)
    
    print(f"Export completed: {output_file}")

if __name__ == "__main__":
    main()
PYTHON_SCRIPT
    
    # Run the Python export script
    if python3 /tmp/export_json.py "$DATABASE_URL" "$json_file"; then
        if [[ -f "$json_file" ]]; then
            local size=$(du -h "$json_file" | cut -f1)
            success "Database exported to JSON ($size)"
        else
            error "Failed to create JSON file"
        fi
    else
        error "Failed to export database to JSON"
    fi
    
    # Clean up
    rm -f /tmp/export_json.py
}

export_files() {
    if [[ "$INCLUDE_FILES" != true ]]; then
        log "Skipping file attachments export"
        return
    fi
    
    local files_dir="$EXPORT_DIR/files"
    log "Exporting file attachments to: $files_dir"
    
    # Default file storage location
    local storage_dir="/var/lib/outline/data"
    
    if [[ ! -d "$storage_dir" ]]; then
        warn "File storage directory not found: $storage_dir"
        return
    fi
    
    mkdir -p "$files_dir"
    
    if cp -r "$storage_dir"/* "$files_dir"/ 2>/dev/null; then
        local size=$(du -sh "$files_dir" | cut -f1)
        success "Files exported ($size)"
    else
        warn "No files found to export or copy failed"
    fi
}

create_metadata() {
    local metadata_file="$EXPORT_DIR/export_metadata.json"
    log "Creating export metadata: $metadata_file"
    
    cat > "$metadata_file" << EOF
{
    "version": "1.0",
    "exportedAt": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
    "exportedBy": "outline-export-cli",
    "format": "$FORMAT",
    "includeFiles": $INCLUDE_FILES,
    "databaseUrl": "$(echo "$DATABASE_URL" | sed 's/:[^:]*@/:***@/')",
    "hostname": "$(hostname)",
    "outlineVersion": "$(node -p "require('/home/ubuntu/outline/package.json').version" 2>/dev/null || echo 'unknown')"
}
EOF
    
    success "Export metadata created"
}

create_readme() {
    local readme_file="$EXPORT_DIR/README.md"
    log "Creating README: $readme_file"
    
    cat > "$readme_file" << EOF
# Outline Export

This directory contains a complete export of an Outline workspace.

## Export Details

- **Exported At**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")
- **Format**: $FORMAT
- **Include Files**: $INCLUDE_FILES

## Contents

EOF

    if [[ "$FORMAT" == "sql" || "$FORMAT" == "both" ]]; then
        echo "- \`database.sql\` - Complete database dump" >> "$readme_file"
    fi
    
    if [[ "$FORMAT" == "json" || "$FORMAT" == "both" ]]; then
        echo "- \`workspace.json\` - Structured workspace data" >> "$readme_file"
    fi
    
    if [[ "$INCLUDE_FILES" == true ]]; then
        echo "- \`files/\` - File attachments and uploads" >> "$readme_file"
    fi
    
    cat >> "$readme_file" << EOF
- \`export_metadata.json\` - Export metadata and settings
- \`README.md\` - This file

## Import

To import this data into another Outline instance, use:

\`\`\`bash
outline-import -d $(basename "$EXPORT_DIR")
\`\`\`

## Manual Import

### Database (SQL)
\`\`\`bash
psql \$DATABASE_URL < database.sql
\`\`\`

### Files
\`\`\`bash
cp -r files/* /var/lib/outline/data/
\`\`\`
EOF
    
    success "README created"
}

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -d|--dir)
            EXPORT_DIR="$2"
            shift 2
            ;;
        -f|--format)
            FORMAT="$2"
            shift 2
            ;;
        --no-files)
            INCLUDE_FILES=false
            shift
            ;;
        -v|--verbose)
            VERBOSE=true
            shift
            ;;
        -h|--help)
            usage
            exit 0
            ;;
        *)
            error "Unknown option: $1"
            ;;
    esac
done

# Validate arguments
if [[ -z "$EXPORT_DIR" ]]; then
    error "Export directory is required. Use -d or --dir option."
fi

if [[ "$FORMAT" != "json" && "$FORMAT" != "sql" && "$FORMAT" != "both" ]]; then
    error "Invalid format: $FORMAT. Use json, sql, or both."
fi

# Check for DATABASE_URL
if [[ -z "$DATABASE_URL" ]]; then
    error "DATABASE_URL environment variable is required."
fi

# Main execution
echo "ðŸš€ Starting Outline export..."
echo "ðŸ“ Export directory: $EXPORT_DIR"
echo "ðŸ“‹ Format: $FORMAT"
echo "ðŸ“Ž Include files: $INCLUDE_FILES"
echo ""

# Warning about export timing
warn "âš ï¸  IMPORTANT: If you just edited documents, wait 5-10 seconds before exporting"
warn "   to ensure all changes are saved. Exporting too quickly after edits may"
warn "   result in missing document content due to autosave timing."
echo ""

check_dependencies
check_database_connection
validate_document_content

# Create export directory
mkdir -p "$EXPORT_DIR"
log "Created export directory: $EXPORT_DIR"

# Export based on format
if [[ "$FORMAT" == "sql" || "$FORMAT" == "both" ]]; then
    export_database_sql
fi

if [[ "$FORMAT" == "json" || "$FORMAT" == "both" ]]; then
    export_database_json
fi

# Export files
export_files

# Create metadata and documentation
create_metadata
create_readme

echo ""
success "Export completed successfully!"
echo "ðŸ“ Export location: $EXPORT_DIR"
echo "ðŸ“Š Export size: $(du -sh "$EXPORT_DIR" | cut -f1)"
echo ""
echo "To import this data, use:"
echo "  outline-import -d $EXPORT_DIR"