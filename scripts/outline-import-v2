#!/bin/bash
# Outline Import Script - Rewritten Version
# Robust import of Outline workspace with proper error handling

set -euo pipefail

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
IMPORT_DIR=""
FORCE=false
SKIP_FILES=false
SKIP_DATABASE=false
VERBOSE=false
DRY_RUN=false
NO_BACKUP=false

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

usage() {
    cat << EOF
Usage: $0 [OPTIONS]

Import Outline workspace data from exported folder

Options:
  -d, --dir DIR         Import directory (required)
  -f, --force          Force import (overwrite existing data)
  --skip-files         Skip file attachments import
  --skip-database      Skip database import
  --dry-run            Show what would be imported without doing it
  --no-backup          Skip database backup
  -v, --verbose        Verbose output
  -h, --help           Show this help

Examples:
  $0 -d /tmp/outline-export
  $0 -d ./backup --force --verbose
  $0 -d ./backup --skip-files --dry-run
EOF
}

log() {
    if [[ "$VERBOSE" == true ]]; then
        echo -e "${BLUE}[INFO]${NC} $1"
    fi
}

success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

error() {
    echo -e "${RED}[ERROR]${NC} $1"
    exit 1
}

check_dependencies() {
    log "Checking dependencies..."
    
    # Check for required commands
    local missing_deps=()
    
    if ! command -v psql &> /dev/null; then
        missing_deps+=("psql (PostgreSQL client)")
    fi
    
    # Check for Python and log which one we're using
    local python_path
    if command -v /usr/bin/python3 &> /dev/null; then
        python_path="/usr/bin/python3"
        log "Using system Python: $python_path"
    elif command -v python3 &> /dev/null; then
        python_path=$(command -v python3)
        warn "Using non-system Python: $python_path (consider using /usr/bin/python3)"
    else
        missing_deps+=("python3")
    fi
    
    # Log Python version for debugging
    if [[ -n "${python_path:-}" ]]; then
        local python_version
        python_version=$("$python_path" --version 2>&1 || echo "Unknown")
        log "Python version: $python_version"
        log "Python executable: $python_path"
    fi
    
    if [[ -f "$IMPORT_DIR/workspace.json" ]] && ! command -v jq &> /dev/null; then
        missing_deps+=("jq (JSON processor)")
    fi
    
    if [[ ${#missing_deps[@]} -gt 0 ]]; then
        error "Missing dependencies: ${missing_deps[*]}"
    fi
    
    # Check for Python dependencies using the detected Python path
    if [[ -n "${python_path:-}" ]]; then
        log "Checking Python dependencies with: $python_path"
        if ! "$python_path" -c "import psycopg2" &> /dev/null; then
            error "Python psycopg2 library not found. Install with: pip3 install psycopg2-binary"
        fi
        log "✅ Python psycopg2 library found"
    fi
    
    success "All dependencies available"
}

validate_import_directory() {
    log "Validating import directory..."
    
    if [[ ! -d "$IMPORT_DIR" ]]; then
        error "Import directory does not exist: $IMPORT_DIR"
    fi
    
    # Check for export metadata
    if [[ ! -f "$IMPORT_DIR/export_metadata.json" ]]; then
        warn "Export metadata not found. This may not be a valid Outline export."
    fi
    
    # Check for at least one data file
    if [[ ! -f "$IMPORT_DIR/database.sql" && ! -f "$IMPORT_DIR/workspace.json" ]]; then
        error "No database files found. Expected database.sql or workspace.json"
    fi
    
    success "Import directory validated"
}

check_database_connection() {
    log "Checking database connection..."
    
    if [[ -z "${DATABASE_URL:-}" ]]; then
        error "DATABASE_URL environment variable is required"
    fi
    
    if ! psql "$DATABASE_URL" -c "SELECT 1;" &> /dev/null; then
        error "Cannot connect to database. Check DATABASE_URL environment variable."
    fi
    
    success "Database connection verified"
}

check_existing_data() {
    log "Checking for existing data..."
    
    local team_count user_count doc_count
    team_count=$(psql "$DATABASE_URL" -t -c "SELECT COUNT(*) FROM teams;" 2>/dev/null | tr -d ' ' || echo "0")
    user_count=$(psql "$DATABASE_URL" -t -c "SELECT COUNT(*) FROM users;" 2>/dev/null | tr -d ' ' || echo "0")
    doc_count=$(psql "$DATABASE_URL" -t -c "SELECT COUNT(*) FROM documents;" 2>/dev/null | tr -d ' ' || echo "0")
    
    if [[ "$team_count" -gt 0 || "$user_count" -gt 0 || "$doc_count" -gt 0 ]]; then
        warn "Existing data found: $team_count teams, $user_count users, $doc_count documents"
        
        if [[ "$FORCE" != true ]]; then
            echo ""
            echo "⚠️  WARNING: This will overwrite existing data!"
            echo "   Teams: $team_count"
            echo "   Users: $user_count" 
            echo "   Documents: $doc_count"
            echo ""
            read -p "Continue? (y/N): " -n 1 -r
            echo
            if [[ ! $REPLY =~ ^[Yy]$ ]]; then
                echo "Import cancelled."
                exit 0
            fi
        fi
    fi
}

import_database_sql() {
    local sql_file="$IMPORT_DIR/database.sql"
    
    if [[ ! -f "$sql_file" ]]; then
        log "No SQL file found, skipping SQL import"
        return
    fi
    
    if [[ "$DRY_RUN" == true ]]; then
        log "[DRY RUN] Would import database from: $sql_file"
        return
    fi
    
    log "Importing database from SQL: $sql_file"
    
    # Create a temporary database for validation
    if [[ "$FORCE" == true ]]; then
        log "Dropping existing schema..."
        psql "$DATABASE_URL" -c "DROP SCHEMA IF EXISTS public CASCADE; CREATE SCHEMA public;" || {
            error "Failed to drop existing schema"
        }
    fi
    
    # Import SQL file with better error handling
    if psql "$DATABASE_URL" -f "$sql_file" -v ON_ERROR_STOP=1; then
        success "Database imported from SQL"
    else
        error "Failed to import database from SQL"
    fi
}

import_database_json() {
    local json_file="$IMPORT_DIR/workspace.json"
    
    if [[ ! -f "$json_file" ]]; then
        log "No JSON file found, skipping JSON import"
        return
    fi
    
    if [[ "$DRY_RUN" == true ]]; then
        log "[DRY RUN] Would import database from: $json_file"
        return
    fi
    
    log "Importing database from JSON: $json_file"
    
    # Use the separate Python script
    local python_script="$SCRIPT_DIR/outline-import-new.py"
    
    if [[ ! -f "$python_script" ]]; then
        error "Python import script not found: $python_script"
    fi
    
    # Determine which Python to use (prefer system Python)
    local python_executable
    if command -v /usr/bin/python3 &> /dev/null; then
        python_executable="/usr/bin/python3"
        log "Using system Python for import: $python_executable"
    elif command -v python3 &> /dev/null; then
        python_executable=$(command -v python3)
        warn "Using non-system Python for import: $python_executable"
    else
        error "No Python3 executable found"
    fi
    
    # Log the Python version being used for the import
    local python_version
    python_version=$("$python_executable" --version 2>&1 || echo "Unknown")
    log "Import Python version: $python_version"
    
    # Build Python command arguments
    local python_args=("$json_file" "$DATABASE_URL")
    
    if [[ "$VERBOSE" == true ]]; then
        python_args+=("--verbose")
    fi
    
    # Run the Python import script
    log "Executing: $python_executable $python_script ${python_args[*]}"
    if "$python_executable" "$python_script" "${python_args[@]}"; then
        success "Database imported from JSON"
    else
        local exit_code=$?
        if [[ $exit_code -eq 1 ]]; then
            warn "Import had some failures but completed"
            warn "Check the logs above for details on what failed"
            warn "You may need to run database migrations first"
            echo ""
            echo "💡 If you see 'relation does not exist' errors, try running:"
            echo "   cd /home/ubuntu/outline && yarn db:migrate"
            echo "   Then re-run the import"
        else
            error "Failed to import database from JSON (exit code: $exit_code)"
        fi
    fi
}

import_files() {
    if [[ "$SKIP_FILES" == true ]]; then
        log "Skipping file attachments import"
        return
    fi
    
    local files_dir="$IMPORT_DIR/files"
    
    if [[ ! -d "$files_dir" ]]; then
        log "No files directory found, skipping file import"
        return
    fi
    
    if [[ "$DRY_RUN" == true ]]; then
        local file_count=$(find "$files_dir" -type f | wc -l)
        local total_size=$(du -sh "$files_dir" | cut -f1)
        log "[DRY RUN] Would import $file_count files ($total_size) from: $files_dir"
        return
    fi
    
    log "Importing file attachments from: $files_dir"
    
    # Default file storage location
    local storage_dir="/var/lib/outline/data"
    
    # Create storage directory if it doesn't exist
    mkdir -p "$storage_dir"
    
    # Copy files with progress indication
    if rsync -av --progress "$files_dir/" "$storage_dir/" 2>/dev/null; then
        # Fix permissions
        chown -R ubuntu:ubuntu "$storage_dir" 2>/dev/null || true
        chmod -R 755 "$storage_dir" 2>/dev/null || true
        
        local size
        size=$(du -sh "$storage_dir" | cut -f1)
        success "Files imported ($size)"
    else
        warn "File import failed or no files found"
    fi
}

show_import_summary() {
    echo ""
    echo "📊 Import Summary"
    echo "=================="
    
    # Show export metadata if available
    if [[ -f "$IMPORT_DIR/export_metadata.json" ]]; then
        local export_date export_version
        export_date=$(jq -r '.exportedAt // "Unknown"' "$IMPORT_DIR/export_metadata.json" 2>/dev/null || echo "Unknown")
        export_version=$(jq -r '.version // "Unknown"' "$IMPORT_DIR/export_metadata.json" 2>/dev/null || echo "Unknown")
        
        echo "📅 Export Date: $export_date"
        echo "🏷️  Export Version: $export_version"
    fi
    
    # Show database statistics
    if [[ "$SKIP_DATABASE" != true ]]; then
        local team_count user_count doc_count collection_count
        team_count=$(psql "$DATABASE_URL" -t -c "SELECT COUNT(*) FROM teams;" 2>/dev/null | tr -d ' ' || echo "0")
        user_count=$(psql "$DATABASE_URL" -t -c "SELECT COUNT(*) FROM users;" 2>/dev/null | tr -d ' ' || echo "0")
        doc_count=$(psql "$DATABASE_URL" -t -c "SELECT COUNT(*) FROM documents;" 2>/dev/null | tr -d ' ' || echo "0")
        collection_count=$(psql "$DATABASE_URL" -t -c "SELECT COUNT(*) FROM collections;" 2>/dev/null | tr -d ' ' || echo "0")
        
        echo "👥 Teams: $team_count"
        echo "👤 Users: $user_count"
        echo "📚 Collections: $collection_count"
        echo "📄 Documents: $doc_count"
    fi
    
    # Show file statistics
    if [[ "$SKIP_FILES" != true && -d "/var/lib/outline/data" ]]; then
        local file_size file_count
        file_size=$(du -sh "/var/lib/outline/data" 2>/dev/null | cut -f1 || echo "0B")
        file_count=$(find "/var/lib/outline/data" -type f 2>/dev/null | wc -l || echo "0")
        echo "📎 Files: $file_count files ($file_size)"
    fi
}

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -d|--dir)
            IMPORT_DIR="$2"
            shift 2
            ;;
        -f|--force)
            FORCE=true
            shift
            ;;
        --skip-files)
            SKIP_FILES=true
            shift
            ;;
        --skip-database)
            SKIP_DATABASE=true
            shift
            ;;
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        --no-backup)
            NO_BACKUP=true
            shift
            ;;
        -v|--verbose)
            VERBOSE=true
            shift
            ;;
        -h|--help)
            usage
            exit 0
            ;;
        *)
            error "Unknown option: $1"
            ;;
    esac
done

# Validate arguments
if [[ -z "$IMPORT_DIR" ]]; then
    error "Import directory is required. Use -d or --dir option."
fi

# Main execution
echo "📥 Starting Outline import..."
echo "📁 Import directory: $IMPORT_DIR"
echo "💪 Force mode: $FORCE"
echo "🏃 Dry run: $DRY_RUN"
echo ""

# Run pre-import checks
check_dependencies
validate_import_directory
check_database_connection

if [[ "$SKIP_DATABASE" != true ]]; then
    check_existing_data
fi

# Import database
if [[ "$SKIP_DATABASE" != true ]]; then
    # Try SQL first, then JSON
    if [[ -f "$IMPORT_DIR/database.sql" ]]; then
        import_database_sql
    elif [[ -f "$IMPORT_DIR/workspace.json" ]]; then
        import_database_json
    else
        error "No database file found to import"
    fi
fi

# Import files
import_files

# Show summary
if [[ "$DRY_RUN" != true ]]; then
    show_import_summary
    echo ""
    success "Import completed successfully!"
    echo ""
    echo "🚀 You can now start Outline and access your imported data."
    echo "🔗 Don't forget to update any configuration if needed."
else
    echo ""
    success "Dry run completed - no changes made"
fi 